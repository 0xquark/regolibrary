{
    "name": "DevOpsBest",
    "description": "",
    "attributes": {
        "armoBuiltin": true
    },
    "version": null,
    "controls": [
        {
            "name": "Naked PODs",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "Don't use naked Pods (that is, Pods not bound to a ReplicaSet or Deployment) if you can avoid it. Naked Pods will not be rescheduled in the event of a node failure.",
            "remediation": "",
            "id": "C-0073",
            "long_description": "Don't use naked Pods (that is, Pods not bound to a ReplicaSet or Deployment) if you can avoid it. Naked Pods will not be rescheduled in the event of a node failure.",
            "test": "Test if pods are not associated to replica-set or deployment, if not \u2013 fail.",
            "controlID": "C-0073",
            "baseScore": 0,
            "rules": [
                {
                    "name": "naked-pods",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Don't use naked Pods (that is, Pods not bound to a ReplicaSet or Deployment) if you can avoid it. Naked Pods will not be rescheduled in the event of a node failure.",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Fails if workload is Pod\ndeny[msga] {\n    pod := input[_]\n\tpod.kind == \"Pod\"\n\tnot pod.metadata.ownerReferences\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v not associated with ReplicaSet or Deployment\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 0,\n\t\t\"failedPaths\": \"metadata\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n\n"
                }
            ]
        },
        {
            "name": "Containers mounting docker socket",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "Mounting docker socket will enable a container to access the docker internals.",
            "remediation": "",
            "id": "C-0074",
            "long_description": "Mounting docker socket will enable a container to access the docker internals.",
            "test": "Check hostpath. If the path is set to /var/run/docker.sock or /var/lib/docker , the container has access to Docker internals - fail.",
            "controlID": "C-0074",
            "baseScore": 0,
            "rules": [
                {
                    "name": "containers-mounting-docker-socket",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Pods",
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Check hostpath. If the path is set to /var/run/docker.sock or /var/lib/docker , the container has access to Docker internals - fail.",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n    volume := pod.spec.volumes[i]\n\thostPath := volume.hostPath\n    isDockerMounting(hostPath)\n\tpath := sprintf(\"spec.volumes[%v].hostPath.path\", [format_int(i, 10)])\n    msga := {\n\t\t\"alertMessage\": sprintf(\"volume: %v in pod: %v has mounting to Docker internals.\", [volume.name, pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [path],\n\t\t\"alertScore\": 0,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\t\n}\n\n\n\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    volume := wl.spec.template.spec.volumes[i]\n\thostPath := volume.hostPath\n    isDockerMounting(hostPath)\n\tpath := sprintf(\"spec.template.spec.volumes[%v].hostPath.path\", [format_int(i, 10)])\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"volume: %v in %v: %v has mounting to Docker internals.\", [ volume.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [path],\n\t\t\"alertScore\": 0,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\ndeny[msga] {\n  \twl := input[_]\n\twl.kind == \"CronJob\"\n\tvolume = wl.spec.jobTemplate.spec.template.spec.volumes[i]\n    hostPath := volume.hostPath\n    isDockerMounting(hostPath)\n\tpath := sprintf(\"spec.jobTemplate.spec.template.spec.volumes[%v].hostPath.path\", [format_int(i, 10)])\n    msga := {\n\t\t\"alertMessage\": sprintf(\"volume: %v in %v: %v has mounting to Docker internals.\", [ volume.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [path],\n\t\t\"alertScore\": 0,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\nisDockerMounting(hostPath) {\n\thostPath.path == \"/var/run/docker.sock\"\n}\n\nisDockerMounting(hostPath) {\n\thostPath.path == \"/var/run/docker\"\n}\n"
                }
            ]
        },
        {
            "name": "Image pull policy is not set to always",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "Using the always pull policy will assure updates to the image repository are propagated to the cluster.",
            "remediation": "",
            "id": "C-0075",
            "long_description": "Using the always pull policy will assure updates to the image repository are propagated to the cluster.",
            "test": "If  imagePullPolicy = always pass, else fail.",
            "controlID": "C-0075",
            "baseScore": 0,
            "rules": [
                {
                    "name": "image-pull-policy-is-not-set-to-always",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Pods",
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "check imagePullPolicy filed, if imagePullPolicy = always pass, else fail.",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n    isBadContainer(container)\n\tpaths = [sprintf(\"spec.containers[%v].image\", [format_int(i, 10)]), sprintf(\"spec.containers[%v].imagePullPolicy\", [format_int(i, 10)])]\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in pod: %v  has 'latest' tag on image but imagePullPolicy is not set to 'Always'\", [container.name, pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 0,\n\t\t\"failedPaths\": paths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\tpaths = [sprintf(\"spec.template.spec.containers[%v].image\", [format_int(i, 10)]), sprintf(\"spec.template.spec.containers[%v].imagePullPolicy\", [format_int(i, 10)])]\n    isBadContainer(container)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in %v: %v  has 'latest' tag on image but imagePullPolicy is not set to 'Always'\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 0,\n\t\t\"failedPaths\": paths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n    wl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tpaths = [sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v].image\", [format_int(i, 10)]), sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v].imagePullPolicy\", [format_int(i, 10)])]\n    isBadContainer(container)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in cronjob: %v  has 'latest' tag on image but imagePullPolicy is not set to 'Always'\", [container.name, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 0,\n\t\t\"failedPaths\": paths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nisBadContainer(container){\n    reg := \":[\\\\w][\\\\w.-]{0,127}(\\/)?\"\n    version := regex.find_all_string_submatch_n(reg, container.image, -1)\n    v := version[_]\n    img := v[_]\n    img == \":latest\"\n    notImagePullPolicy(container)\n}\n\n# No image tag or digest (== latest)\nisBadContainer(container){\n    not isTagImage(container.image)\n    notImagePullPolicy(container)\n}\n\n# image tag is only letters (== latest)\nisBadContainer(container){\n    imate+tag := isTagImage(container.image)\n    notImagePullPolicy(container)\n}\n\nnotImagePullPolicy(container) {\n     container.imagePullPolicy == \"Never\"\n}\n\n\nnotImagePullPolicy(container) {\n     container.imagePullPolicy == \"IfNotPresent\"\n}\n\nisTagImage(image) = img{\n    reg := \":[\\\\w][\\\\w.-]{0,127}(\\/)?\"\n    version := regex.find_all_string_submatch_n(reg, image, -1)\n    v := version[_]\n    img := v[_]\n    not endswith(img, \"/\")\n}"
                }
            ]
        },
        {
            "name": "Label usage for resources",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "Define and use labels that identify semantic attributes of your application or Deployment, such as { app: myapp, tier: frontend, phase: test, deployment: v3 }. You can use these labels to select the appropriate Pods for other resources.",
            "remediation": "",
            "id": "C-0076",
            "long_description": "Define and use labels that identify semantic attributes of your application or Deployment, such as { app: myapp, tier: frontend, phase: test, deployment: v3 }. You can use these labels to select the appropriate Pods for other resources.",
            "test": "Test will check if a certain set of labels is defined, this is a configurable control. Initial list: app, tier, phase, version, owner, env.",
            "controlID": "C-0076",
            "baseScore": 0,
            "rules": [
                {
                    "name": "label-usage-for-resources",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Pods",
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "check if a certain set of labels is defined, this is a configurable control. Initial list: app, tier, phase, version, owner, env.",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n# Deny mutating action unless user is in group owning the resource\n\n\n\ndeny[msga] {\n\n\tpod := input[_]\n\tpod.kind == \"Pod\"\n\tmetadata := pod.metadata\n\tpath := noLabelOrNoLabelUsage(metadata, \"\")\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"in the following pods a certain set of labels is not defined: %v\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 0,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n     }\n}\n\n\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\twlMetadata := wl.metadata\n\tpodMetadata := wl.spec.template.metadata\n\tbegginingOfPodPath := \"spec.template.\"\n\tpath := noLabelUsage(wlMetadata, podMetadata, begginingOfPodPath)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v a certain set of labels is not defined:\", [wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 0,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n#handles cronjob\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\twlMetadata := wl.metadata\n\tpodMetadata := wl.spec.jobTemplate.spec.template.metadata\n\tbegginingOfPodPath := \"spec.jobTemplate.spec.template.\"\n\tpath := noLabelUsage(wlMetadata, podMetadata, begginingOfPodPath)\n\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"the following cronjobs a certain set of labels is not defined: %v\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 0,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n\n# There is no label-usage in WL and also for his Pod\nnoLabelUsage(wlMetadata, podMetadata, begginingOfPodPath) = path{\n\tpath1 := noLabelOrNoLabelUsage(wlMetadata, \"\")\n\tpath2 := noLabelOrNoLabelUsage(podMetadata, begginingOfPodPath)\n\tpath = array.concat(path1, path2)\n}\n\n# There is label-usage for WL but not for his Pod\nnoLabelUsage(wlMetadata, podMetadata, begginingOfPodPath) = path{\n\tnot noLabelOrNoLabelUsage(wlMetadata, \"\")\n\tpath := noLabelOrNoLabelUsage(podMetadata, begginingOfPodPath)\n}\n\n# There is no label-usage for WL but there is for his Pod\nnoLabelUsage(wlMetadata, podMetadata, begginingOfPodPath) = path{\n\tnot noLabelOrNoLabelUsage(podMetadata, begginingOfPodPath)\n\tpath := noLabelOrNoLabelUsage(wlMetadata, \"\")\n}\n\nnoLabelOrNoLabelUsage(metadata, begginingOfPath) = path{\n\tnot metadata.labels\n\tpath = [sprintf(\"%vmetadata\", [begginingOfPath])]\n}\n\nnoLabelOrNoLabelUsage(metadata, begginingOfPath) = path{\n\tlabels := metadata.labels\n\tnot isDesiredLabel(labels)\n\tpath = [sprintf(\"%vmetadata.labels\", [begginingOfPath])]\n}\n\nisDesiredLabel(labels) {\n\t_ = labels.app\n}\n\nisDesiredLabel(labels) {\n\t_ = labels.tier\n}\n\nisDesiredLabel(labels) {\n\t_ = labels.phase\n}\n\nisDesiredLabel(labels) {\n\t_ = labels.version\n}\n\nisDesiredLabel(labels){\n\t_ = labels.owner\n}\n\nisDesiredLabel(labels) {\n\t_ = labels.env\n}"
                }
            ]
        },
        {
            "name": "K8s common labels usage",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "Use the Kubernetes common labels for common use cases. These standardized labels enrich the metadata in a way that allows tools, including kubectl and dashboard, to work in an interoperable way.",
            "remediation": "",
            "id": "C-0077",
            "long_description": "Use the Kubernetes common labels for common use cases. These standardized labels enrich the metadata in a way that allows tools, including kubectl and dashboard, to work in an interoperable way.",
            "test": "Test will check if the list of label that start with app.kubernetes.io/ are defined.",
            "controlID": "C-0077",
            "baseScore": 0,
            "rules": [
                {
                    "name": "K8s common labels usage",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Pods",
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Check if the list of label that start with app.kubernetes.io/ are defined.",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n# Deny mutating action unless user is in group owning the resource\n\n\n\ndeny[msga] {\n\n\tpod := input[_]\n\tpod.kind == \"Pod\"\n\tmetadata := pod.metadata\n\tpath := noK8sLabelOrNoK8sLabelUsage(metadata, \"\")\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"in the following pod the kubernetes common labels are not defined: %v\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 0,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n     }\n}\n\n\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\twlMetadata := wl.metadata\n\tpodMetadata := wl.spec.template.metadata\n\tbegginingOfPodPath := \"spec.template.\"\n\tpath := noK8sLabelUsage(wlMetadata, podMetadata, begginingOfPodPath)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v the kubernetes common labels are is not defined:\", [wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 0,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n#handles cronjob\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\twlMetadata := wl.metadata\n\tpodMetadata := wl.spec.jobTemplate.spec.template.metadata\n\tbegginingOfPodPath := \"spec.jobTemplate.spec.template.\"\n\tpath := noK8sLabelUsage(wlMetadata, podMetadata, begginingOfPodPath)\n\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"the following cronjobs the kubernetes common labels are not defined: %v\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 0,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n\n\n# There is no label-usage in WL and also for his Pod\nnoK8sLabelUsage(wlMetadata, podMetadata, begginingOfPodPath) = path{\n\tpath1 := noK8sLabelOrNoK8sLabelUsage(wlMetadata, \"\")\n\tpath2 := noK8sLabelOrNoK8sLabelUsage(podMetadata, begginingOfPodPath)\n\tpath = array.concat(path1, path2)\n}\n\n# There is label-usage for WL but not for his Pod\nnoK8sLabelUsage(wlMetadata, podMetadata, begginingOfPodPath) = path{\n\tnot noK8sLabelOrNoK8sLabelUsage(wlMetadata, \"\")\n\tpath := noK8sLabelOrNoK8sLabelUsage(podMetadata, begginingOfPodPath)\n}\n\n# There is no label-usage for WL but there is for his Pod\nnoK8sLabelUsage(wlMetadata, podMetadata, begginingOfPodPath) = path{\n\tnot noK8sLabelOrNoK8sLabelUsage(podMetadata, begginingOfPodPath)\n\tpath := noK8sLabelOrNoK8sLabelUsage(wlMetadata, \"\")\n}\n\nnoK8sLabelOrNoK8sLabelUsage(metadata, begginingOfPath) = path{\n\tnot metadata.labels\n\tpath = [sprintf(\"%vmetadata\", [begginingOfPath])]\n}\n\nnoK8sLabelOrNoK8sLabelUsage(metadata, begginingOfPath) = path{\n\tlabels := metadata.labels\n\tnot allKubernetesLabels(labels)\n\tpath = [sprintf(\"%vmetadata.labels\", [begginingOfPath])]\n}\n\nallKubernetesLabels(labels){\n\t_ := labels[name]\n\tstartswith(name, \"app.kubernetes.io/\")\n\n}\n"
                }
            ]
        },
        {
            "name": "Pods in default namespace",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "It is recommended to avoid running any PODs in cluster without explicit namespace assignment. This control identifies all the PODs running in the default namespace.",
            "remediation": "Create necessary namespaces and move all the PODs from default namespace to the newly created namespaces.",
            "id": "C-0061",
            "long_description": "It is recommended to avoid running any PODs in cluster without explicit namespace assignment. This control identifies all the PODs running in the default namespace.",
            "test": "Check that there are no pods in the 'default' namespace",
            "controlID": "C-0061",
            "baseScore": 4.0,
            "rules": [
                {
                    "name": "pods-in-default-namespace",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "Pod",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n    pod.metadata.namespace == \"default\"\n\tpath := \"metadata.namespace\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v is running in the 'default' namespace\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\twl.metadata.namespace == \"default\"\n\tpath := \"metadata.namespace\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has pods running in the 'default' namespace\", [wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n    wl := input[_]\n\twl.kind == \"CronJob\"\n    wl.metadata.namespace == \"default\"\n\tpath := \"metadata.namespace\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"CronJob: %v had pods  running in the 'default' namespace\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n"
                }
            ]
        },
        {
            "name": "Container hostPort",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "Configuring hostPort limits you to a particular port, and if any two workloads that specify the same HostPort they cannot be deployed to the same node. Therefore, if the number of replica of such workload is higher than the number of nodes, the deployment will fail.",
            "remediation": "Avoid usage of hostPort unless it is absolutely necessary. Use NodePort / ClusterIP instead.",
            "id": "C-0044",
            "long_description": "Workloads (like pod, deployment, etc) that contain a container with hostport. The problem that arises is that if the scale of your workload is larger than the number of nodes in your Kubernetes cluster, the deployment fails. And any two workloads that specify the same HostPort cannot be deployed to the same node. in addition, if the host where your pods are running becomes unavailable, Kubernetes reschedules the pods to different nodes. Thus, if the IP address for your workload changes, external clients of your application will lose access to the pod. The same thing happens when you restart your pods \u2014 Kubernetes reschedules them to a different node.\u00a0",
            "test": "Check for each workload (with container) if it exists inside the container hostPort.\u00a0\u00a0",
            "controlID": "C-0044",
            "baseScore": 4.0,
            "example": "@controls/examples/c044.yaml",
            "rules": [
                {
                    "name": "container-hostPort",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "Pod",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "fails if container has hostPort",
                    "remediation": "Make sure you do not configure hostPort for the container, if necessary use NodePort / ClusterIP",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Fails if pod has container with hostPort\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n    container := pod.spec.containers[i]\n\tbegginingOfPath := \"spec.\"\n\tpath := isHostPort(container, i, begginingOfPath)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v has Host-port\", [ container.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if workload has container with hostPort\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n\tbegginingOfPath := \"spec.template.spec.\"\n    path := isHostPort(container, i, begginingOfPath)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   has Host-port\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if cronjob has container with hostPort\ndeny[msga] {\n  \twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tbegginingOfPath := \"spec.jobTemplate.spec.template.spec.\"\n    path := isHostPort(container, i, begginingOfPath)\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   has Host-port\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n\nisHostPort(container, i, begginingOfPath) = path {\n\tpath = [sprintf(\"%vcontainers[%v].ports[%v].hostPort\", [begginingOfPath, format_int(i, 10), format_int(j, 10)]) | port = container.ports[j];  port.hostPort]\n\tcount(path) > 0\n}\n"
                }
            ]
        },
        {
            "name": "Host PID/IPC privileges",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "Containers should be as isolated as possible from the host machine. The hostPID and hostIPC fields in Kubernetes may excessively expose the host to potentially malicious actions.",
            "remediation": "Remove hostPID and hostIPC privileges unless they are absolutely necessary.",
            "id": "C-0038",
            "controlID": "C-0038",
            "baseScore": 5.0,
            "example": "@controls/examples/c038.yaml",
            "rules": [
                {
                    "name": "host-pid-ipc-privileges",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "Pod",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Containers should be as isolated as possible from the host machine. The hostPID and hostIPC fields in Kubernetes may excessively expose the host to potentially malicious actions.",
                    "remediation": "Make sure that the fields hostIPC and hostPID in the pod spec are not set to true (set to false or not present)",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Fails if pod has hostPID enabled\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n\tisHostPID(pod.spec)\n\tpath := \"spec.hostPID\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v has hostPID enabled\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if pod has hostIPC enabled\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n\tisHostIPC(pod.spec)\n\tpath := \"spec.hostIPC\"\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v has hostIPC enabled\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n\n# Fails if workload has hostPID enabled\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tisHostPID(wl.spec.template.spec)\n\tpath := \"spec.template.spec.hostPID\"\n    msga := {\n\t\"alertMessage\": sprintf(\"%v: %v has a pod with hostPID enabled\", [wl.kind, wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if workload has hostIPC enabled\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tisHostIPC(wl.spec.template.spec)\n\tpath := \"spec.template.spec.hostIPC\"\n    msga := {\n\t\"alertMessage\": sprintf(\"%v: %v has a pod with hostIPC enabled\", [wl.kind, wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if cronjob has hostPID enabled\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tisHostPID(wl.spec.jobTemplate.spec.template.spec)\n\tpath := \"spec.jobTemplate.spec.template.spec.hostPID\"\n    msga := {\n\t\"alertMessage\": sprintf(\"CronJob: %v has a pod with hostPID enabled\", [wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if cronjob has hostIPC enabled\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tisHostIPC(wl.spec.jobTemplate.spec.template.spec)\n\tpath := \"spec.jobTemplate.spec.template.spec.hostIPC\"\n    msga := {\n\t\"alertMessage\": sprintf(\"CronJob: %v has a pod with hostIPC enabled\", [wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"failedPaths\": [path],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Check that hostPID and hostIPC are set to false. Default is false. Only in pod spec\n\n\nisHostPID(podspec){\n    podspec.hostPID == true\n}\n\nisHostIPC(podspec){\n     podspec.hostIPC == true\n}"
                }
            ]
        },
        {
            "name": "Privileged container",
            "attributes": {
                "armoBuiltin": true,
                "microsoftMitreColumns": [
                    "Privilege escalation"
                ]
            },
            "description": "Potential attackers may gain access to privileged containers and inherit access to the host resources. Therefore, it is not recommended to deploy privileged containers unless it is absolutely necessary. This control identifies all the privileged Pods.",
            "example": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged\nspec:\n  containers:\n    - name: pause\n      image: k8s.gcr.io/pause\n      securityContext:\n          privileged: true # This field triggers failure!\n",
            "remediation": "Remove privileged capabilities by setting the securityContext.privileged to false. If you must deploy a Pod as privileged, add other restriction to it, such as network policy, Seccomp etc and still remove all unnecessary capabilities. Use the exception mechanism to remove unnecessary notifocations.",
            "id": "C-0057",
            "long_description": "A privileged container is a container that has all the capabilities of the host machine, which lifts all the limitations regular containers have. Practically, this means that privileged containers can do almost every action that can be performed directly on the host. Attackers who gain access to a privileged container or have permissions to create a new privileged container (by using the compromised pod\u2019s service account, for example), can get access to the host\u2019s resources.",
            "test": "Check in POD spec if securityContext.privileged == true, if so raise an alert.",
            "controlID": "C-0057",
            "baseScore": 8.0,
            "rules": [
                {
                    "name": "rule-privilege-escalation",
                    "attributes": {
                        "m$K8sThreatMatrix": "Privilege Escalation::privileged container",
                        "mitre": "Privilege Escalation",
                        "mitreCode": "TA0004",
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "Pod",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "determines if pods/deployments defined as privileged true",
                    "remediation": "avoid defining pods as privilleged",
                    "ruleQuery": "",
                    "rule": "package armo_builtins\n# Deny mutating action unless user is in group owning the resource\n\n\n#privileged pods\ndeny[msga] {\n\n\tpod := input[_]\n\tpod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\tbegginingOfPath := \"spec.\"\n\tpath := isPrivilegedContainer(container, i, begginingOfPath)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"the following pods are defined as privileged: %v\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n     }\n}\n\n\n#handles majority of workload resources\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\tbegginingOfPath := \"spec.template.spec.\"\n\tpath := isPrivilegedContainer(container, i, begginingOfPath)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is defined as privileged:\", [wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n#handles cronjob\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tbegginingOfPath := \"spec.jobTemplate.spec.template.spec.\"\n\tpath := isPrivilegedContainer(container, i, begginingOfPath)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"the following cronjobs are defined as privileged: %v\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n\n# Only SYS_ADMIN capabilite\nisPrivilegedContainer(container, i, begginingOfPath) = path {\n\tnot container.securityContext.privileged == true\n\tpath = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [begginingOfPath, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path) > 0\n}\n\n# Only securityContext.privileged == true\nisPrivilegedContainer(container, i, begginingOfPath) = path {\n\tcontainer.securityContext.privileged == true\n\tpath1 = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [begginingOfPath, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path1) < 1\n\tpath = [sprintf(\"%vcontainers[%v].securityContext.privileged\", [begginingOfPath, format_int(i, 10)])]\n}\n\n# SYS_ADMIN capabilite && securityContext.privileged == true\nisPrivilegedContainer(container, i, begginingOfPath) = path {\n\tpath1 = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [begginingOfPath, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path1) > 0\n\tcontainer.securityContext.privileged == true\n\tpath = array.concat(path1, [sprintf(\"%vcontainers[%v].securityContext.privileged\", [begginingOfPath, format_int(i, 10)])])\n}"
                }
            ]
        },
        {
            "name": "Resources CPU limit and request",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "This control identifies all Pods for which the CPU limit is not set.",
            "remediation": "Set the CPU limit or use exception mechanism to avoid unnecessary notifications.",
            "id": "C-0050",
            "controlID": "C-0050",
            "rules": [
                {
                    "name": "resources-cpu-limit-and-request",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "Pod",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "CPU limits and requests are not set.",
                    "remediation": "Ensure CPU limits and requests are set.",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Fails if pod doas not have container with CPU-limit or request\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n    container := pod.spec.containers[i]\n\tnot request_or_limit_cpu(container)\n\tpath := sprintf(\"spec.containers[%v]\", [format_int(i, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v does not have CPU-limit or request\", [ container.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if workload doas not have container with CPU-limit or request\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n    not request_or_limit_cpu(container)\n\tpath := sprintf(\"spec.template.spec.containers[%v]\", [format_int(i, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   does not have CPU-limit or request\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if cronjob doas not have container with CPU-limit or request\ndeny[msga] {\n  \twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n    not request_or_limit_cpu(container)\n\tpath := sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v]\", [format_int(i, 10)])\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   does not have CPU-limit or request\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nrequest_or_limit_cpu(container) {\n\tcontainer.resources.limits.cpu\n\tcontainer.resources.requests.cpu\n}\n"
                }
            ]
        },
        {
            "name": "Resources memory limit and request",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "This control identifies all Pods for which the memory limit is not set.",
            "remediation": "Set the memory limit or use exception mechanism to avoid unnecessary notifications.",
            "id": "C-0004",
            "controlID": "C-0004",
            "example": "@controls/examples/c004.yaml",
            "rules": [
                {
                    "name": "resources-memory-limit-and-request",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "Pod",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "memory limits and requests are not set.",
                    "remediation": "Ensure memory limits and requests are set.",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Fails if pod doas not have container with memory-limit or request\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n    container := pod.spec.containers[i]\n\tnot request_or_limit_memory(container)\n\tpath := sprintf(\"spec.containers[%v]\", [format_int(i, 10)])\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v does not have memory-limit or request\", [ container.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if workload doas not have container with memory-limit or request\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n    not request_or_limit_memory(container)\n\tpath := sprintf(\"spec.template.spec.containers[%v]\", [format_int(i, 10)])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   does not have memory-limit or request\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if cronjob doas not have container with memory-limit or request\ndeny[msga] {\n  \twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n    not request_or_limit_memory(container)\n\tpath := sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v]\", [format_int(i, 10)])\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   does not have memory-limit or request\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nrequest_or_limit_memory(container) {\n\tcontainer.resources.limits.memory\n\tcontainer.resources.requests.memory\n}\n"
                }
            ]
        },
        {
            "name": "Configured liveness probe",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "Liveness probe is not configured. It is necessary to restart stuck PODs.",
            "remediation": "Ensure Liveness probe is configured.",
            "id": "C-0056",
            "controlID": "C-0056",
            "rules": [
                {
                    "name": "configured-liveness-probe",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "Pod",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Liveness probe is not configured",
                    "remediation": "Ensure Liveness probe is configured",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Fails if pod doas not have container with livenessProbe\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n    container := pod.spec.containers[i]\n\tnot container.livenessProbe\n\tpath := sprintf(\"spec.containers[%v]\", [format_int(i, 10)])\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v does not have livenessProbe\", [ container.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if workload doas not have container with livenessProbe\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n    not container.livenessProbe\n\tpath := sprintf(\"spec.template.spec.containers[%v]\", [format_int(i, 10)])\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   does not have livenessProbe\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if cronjob doas not have container with livenessProbe\ndeny[msga] {\n  \twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n    not container.livenessProbe\n\tpath := sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v]\", [format_int(i, 10)])\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   does not have livenessProbe\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n"
                }
            ]
        },
        {
            "name": "Configured readiness probe",
            "attributes": {
                "armoBuiltin": true
            },
            "description": "Readiness probe is not configured. It is necessary to control network traffic to the POD.",
            "remediation": "Ensure Readiness probe is configured.",
            "id": "C-0018",
            "controlID": "C-0018",
            "example": "@controls/examples/c018.yaml",
            "rules": [
                {
                    "name": "configured-readiness-probe",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "*"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet",
                                "Job",
                                "Pod",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Readiness probe is not configured",
                    "remediation": "Ensure Readiness probe is configured",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Fails if pod doas not have container with readinessProbe\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n    container := pod.spec.containers[i]\n\tnot container.readinessProbe\n\tpath := sprintf(\"spec.containers[%v]\", [format_int(i, 10)])\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v does not have readinessProbe\", [ container.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if workload doas not have container with readinessProbe\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n    not container.readinessProbe\n\tpath := sprintf(\"spec.template.spec.containers[%v]\", [format_int(i, 10)])\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   does not have readinessProbe\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if cronjob doas not have container with readinessProbe\ndeny[msga] {\n  \twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n    not container.readinessProbe\n\tpath := sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v]\", [format_int(i, 10)])\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   does not have readinessProbe\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n"
                }
            ]
        }
    ]
}